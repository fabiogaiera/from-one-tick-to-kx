Transitioning to KX Products: Exploring a Series of Use Cases

Migration projects are tough quite often. Besides the unexpected technical challenges that might appear through the migration process, the new technology awakes reluctancy to some people within the organization: In the case of kdb+ as a new technology to adopt for time series databases, the most prominent criticisms our PO faced were: 

- licensing costs, 
- the lack of performance metrics: vendor-published benchmarks are rare o biased, 
- a difficult technology to learn, 
- lack of professionals in Switzerland specialized in kdb+ 

Beyond the criticisms (Many times without foundations), I would like to give a brief description of my experience exploring simple use cases. 

While migrating tick data to kdb+, one of the more straightforward aspects is handling raw trade and quote data. This is because such data can often be re-sourced from market data providers. Therefore, the main focus during migration lies in rethinking the architecture of the data analytics platform itself.

By shifting to the kdb+ times series database, teams can take full advantage of its performance and expressiveness, among other powerful features. This transition also enables seamless integration with existing Python-based analytics platforms through PyKX, resulting in a more flexible and scalable architecture.

It is well-known that the syntactic sugar of kdb+/q can be sometimes quite difficult for a newbie. Being a niche technology, LLMs won't help you to accelerate your learning, as they weren't trained with vast amount of data, in comparison with Python. However, I found the KX community very supportive, answering from the most naive questions to the most complicated ones. Having the full awareness of what you're doing has a cost, but at the end it's worth to have it